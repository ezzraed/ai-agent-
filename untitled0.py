# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NVkMq0O_mk5YgMhTCVVSI5GnIaJlesE1
"""

pip install pandas transformers sentence-transformers faiss-cpu

import pandas as pd

# Load the data
df = pd.read_csv("jordan_transactions.csv")  # if it's in the same directory


# Preview data
print(df.head())

def safe_format(row):
    return f"Date: {row.get('Transaction Date', '')}, Amount: {row.get('Amount', '')}, Category: {row.get('Category', '')}, Description: {row.get('Details', '')}"

documents = df.apply(safe_format, axis=1).tolist()

from sentence_transformers import SentenceTransformer
import numpy as np

# Load sentence embedding model
embedder = SentenceTransformer('all-MiniLM-L6-v2')

# Generate embeddings
embeddings = embedder.encode(documents, convert_to_tensor=False)

import faiss

# Create FAISS index
dimension = embeddings[0].shape[0]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))

# Save mapping of doc index to actual text
id_to_doc = {i: doc for i, doc in enumerate(documents)}

from transformers import pipeline

# Load a generative model
rag_pipeline = pipeline("text2text-generation", model="google/flan-t5-base")

def query_rag_system(query, top_k=5):
    # Embed the query
    query_embedding = embedder.encode([query])[0]

    # Search in FAISS
    D, I = index.search(np.array([query_embedding]), top_k)
    retrieved_docs = [id_to_doc[i] for i in I[0]]

    # Concatenate retrieved context
    context = "\n".join(retrieved_docs)

    # Generate response
    input_text = f"Context:\n{context}\n\nQuestion: {query}"
    response = rag_pipeline(input_text, max_new_tokens=200)[0]['generated_text']
    return response

query = "What were the largest transactions C MALL?"
print(query_rag_system(query))

pip install pandas faiss-cpu sentence-transformers transformers

import pandas as pd

# Load the uploaded dataset
df = pd.read_csv("jordan_transactions.csv")

# Show the first few rows and columns
print(df.head())
print(df.columns)

# Replace these with your actual column names if needed
documents = df.apply(
    lambda row: f"On {row['transaction_date']}, {row['transaction_amount']} was spent on {row['transaction_type']}",
    axis=1
).tolist()

from sentence_transformers import SentenceTransformer

embedder = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = embedder.encode(documents, convert_to_tensor=False)

import faiss
import numpy as np

dimension = embeddings[0].shape[0]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))

# Map index to the document
id_to_doc = {i: doc for i, doc in enumerate(documents)}

from transformers import pipeline

# Load a generative model
generator = pipeline("text2text-generation", model="google/flan-t5-base")

def query_rag(query, top_k=5):
    query_embedding = embedder.encode([query])[0]
    D, I = index.search(np.array([query_embedding]), top_k)

    context = "\n".join([id_to_doc[i] for i in I[0]])
    prompt = f"Context:\n{context}\n\nQuestion: {query}"

    response = generator(prompt, max_new_tokens=200)[0]["generated_text"]
    return response

print(query_rag("all transaction  for C Mall"))

print(query_rag("How much was spent on groceries in April?"))

print(query_rag("show me all failed transactions at Z Mall last week ?"))

print(query_rag("How much was spent on groceries in april?"))